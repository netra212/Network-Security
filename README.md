# üõ°Ô∏è Network Security Threat Detection using Machine Learning

A robust and production-ready machine learning pipeline designed to detect **phishing threats in network environments**. This project leverages a modular architecture with comprehensive logging, experiment tracking using MLflow, and collaboration/version control via DagsHub. It covers the full ML lifecycle including data ingestion, validation, transformation, model training, and evaluation.

---

## üöÄ Project Highlights

- ‚úÖ **Automated ML Pipeline**: Ingestion ‚Üí Validation ‚Üí Transformation ‚Üí Training
- üì¶ **End-to-End Logging**: Captures every stage of pipeline execution
- üìà **High Performance**:  
  - **Train F1 Score**: `0.9909`  
  - **Test F1 Score**: `0.9747`
- üìä **MLflow + DagsHub**: Integrated experiment tracking & collaboration
- üß™ **Reproducible Artifacts**: All inputs/outputs are tracked and versioned
- üê≥ **Containerized**: Dockerized for reproducibility and deployment

---

## üìÇ Project Structure

```plaintext
‚îú‚îÄ‚îÄ .github/workflows/main.yaml         # CI/CD GitHub Actions Workflow
‚îú‚îÄ‚îÄ Artifacts/                          # Generated pipeline artifacts
‚îú‚îÄ‚îÄ data_schema/schema.yaml             # Data schema for validation
‚îú‚îÄ‚îÄ final_model/                        # Trained model outputs
‚îú‚îÄ‚îÄ Logs/                               # Runtime logs
‚îú‚îÄ‚îÄ mlruns/                             # MLflow experiment tracking data
‚îú‚îÄ‚îÄ Network_Data/phisingData.csv        # Raw dataset
‚îú‚îÄ‚îÄ Networksecurity/                    # Core pipeline package
‚îÇ   ‚îú‚îÄ‚îÄ cloud/s3_syncer.py              # AWS S3 sync script
‚îÇ   ‚îú‚îÄ‚îÄ components/                     # Ingestion, validation, transformation, training
‚îÇ   ‚îú‚îÄ‚îÄ constants/                      # Static pipeline configurations
‚îÇ   ‚îú‚îÄ‚îÄ entity/                         # Data & artifact entities
‚îÇ   ‚îú‚îÄ‚îÄ exception/                      # Custom exception handling
‚îÇ   ‚îú‚îÄ‚îÄ logging/                        # Logging configurations
‚îÇ   ‚îú‚îÄ‚îÄ pipeline/                       # Batch prediction & training scripts
‚îÇ   ‚îî‚îÄ‚îÄ utils/                          # Utility functions (general + ML-specific)
‚îú‚îÄ‚îÄ Templates/table.html                # UI template
‚îú‚îÄ‚îÄ valid_data/test.csv                 # Cleaned test data
‚îú‚îÄ‚îÄ .env                                # Environment variables
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ app.py                              # App script (API / Streamlit)
‚îú‚îÄ‚îÄ Dockerfile                          # Docker container definition
‚îú‚îÄ‚îÄ Main.py                             # Entry point for training
‚îú‚îÄ‚îÄ push_data.py                        # Data push script
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ requirements.txt                    # Python dependencies
‚îî‚îÄ‚îÄ setup.py                            # Installation script
```

---

### ‚úÖ Model Performance Summary

Metric	          Training Set	        Test Set
F1 Score	        0.9909	             0.9747
Precision	        0.9896	             0.9728
Recall	            0.9922	             0.9767

> üîç Model shows excellent generalization and robustness with very minor performance drop between train and test datasets.

---

### ‚öôÔ∏è Key Technologies Used

Category	                Tools & Technologies

Programming Language	        Python 3.10
ML Libraries	                scikit-learn, pandas, NumPy
Imputation Technique	        KNNImputer (n_neighbors=3)
Model Tracking	                MLflow (integrated with DagsHub)
Cloud Storage	                AWS S3 (via s3_syncer.py)
Logging	                        Python logging module with centralized custom logs
Containerization	            Docker
CI/CD	                        GitHub Actions (.github/workflows/main.yaml)
Web API / UI	                FastAPI or Streamlit (app.py)
Project Structure	            Modular Python package with reusable components

---

### üîÅ Training & Evaluation Pipeline

Pipeline Stage	                Description

1. Data Ingestion	            Loads raw dataset, splits into train/test, and saves to artifact directory.

2. Validation	                Validates schema and column consistency (handles mismatches gracefully).

3. Transformation	            Applies KNNImputer, feature engineering, and serializes transformers.

4. Model Training	            Trains classification model using scikit-learn.

5. Evaluation	                Calculates metrics (F1, precision, recall) on both train and test datasets.

6. Artifact                     Logging	Stores model, transformer, and metric artifacts with time-stamped paths.

7. Experiment Tracking	        Logs everything to MLflow and DagsHub for versioning and comparison.

---

### üß™ How to Reproduce

1. Install Dependencies
    ```pip install -r requirements.txt```

2. Run Training Pipeline
    ```python Main.py```

3. Launch API / Web App
    ```python app.py```
